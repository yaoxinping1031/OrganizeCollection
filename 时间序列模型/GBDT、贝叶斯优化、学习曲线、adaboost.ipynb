{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08888888888888893"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_test = [0, 0, 2, 2, 4]\n",
    "y_pred = [-1/3, -1/3, 7/3, 7/3, 4]\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了新模型的残差后，便可以继续构造新的决策树来拟合残差，直到系统的均方误差 MSE 达到指定要求或者迭代次数达到指定条件时，便停止迭代，形成最终模型。因为 GBDT 算法是不停地拟合新模型的残差，所以随着新的迭代，整个系统的残差会越来越小，或者更精确的说，系统的均方误差 MSE 会越来越小，从而使得模型更加准确。\n",
    "\n",
    "### 4. GBDT算法的简单代码实现\n",
    "\n",
    "GBDT模型既可以做分类分析，也可以做回归分析，分别对应的模型为: **GBDT分类模型**（GradientBoostingClassifier）及 **GBDT回归模型**（GradientBoostingRegressor）。GBDT 分类模型的弱学习器是分类决策树模型，GBDT 回归模型的弱学习器是回归决策树模型。\n",
    "\n",
    "* **GBDT 分类模型**的简单演示代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 0, 0, 1, 1]\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=123)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(model.predict([[5, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **GBDT回归模型**的简单演示代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.54908866]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [1, 2, 3, 4, 5]\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=123)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(model.predict([[5, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、案例实战：产品定价模型\n",
    "\n",
    "### 1. 模型搭建\n",
    "\n",
    "首先读取1000条图书价格数据，特征变量有图书的页数，类别，彩印和纸张，目标变量是图书的定价。这里为了方便演示，只选取了4个特征变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>页数</th>\n",
       "      <th>类别</th>\n",
       "      <th>彩印</th>\n",
       "      <th>纸张</th>\n",
       "      <th>价格</th>\n",
       "      <th>出版地</th>\n",
       "      <th>字数</th>\n",
       "      <th>出版时间</th>\n",
       "      <th>印刷数量</th>\n",
       "      <th>作者平均年龄</th>\n",
       "      <th>印张</th>\n",
       "      <th>印刷次数</th>\n",
       "      <th>版本</th>\n",
       "      <th>作者数量</th>\n",
       "      <th>月销售量</th>\n",
       "      <th>累计销售量</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207</td>\n",
       "      <td>技术类</td>\n",
       "      <td>0</td>\n",
       "      <td>双胶纸</td>\n",
       "      <td>60</td>\n",
       "      <td>北京市</td>\n",
       "      <td>51000</td>\n",
       "      <td>2019</td>\n",
       "      <td>35000</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>技术类</td>\n",
       "      <td>0</td>\n",
       "      <td>双胶纸</td>\n",
       "      <td>62</td>\n",
       "      <td>北京市</td>\n",
       "      <td>25000</td>\n",
       "      <td>2019</td>\n",
       "      <td>48000</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>技术类</td>\n",
       "      <td>0</td>\n",
       "      <td>双胶纸</td>\n",
       "      <td>62</td>\n",
       "      <td>北京市</td>\n",
       "      <td>88000</td>\n",
       "      <td>2019</td>\n",
       "      <td>27000</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>498</td>\n",
       "      <td>10080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218</td>\n",
       "      <td>技术类</td>\n",
       "      <td>0</td>\n",
       "      <td>双胶纸</td>\n",
       "      <td>64</td>\n",
       "      <td>北京市</td>\n",
       "      <td>21000</td>\n",
       "      <td>2019</td>\n",
       "      <td>20000</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "      <td>技术类</td>\n",
       "      <td>0</td>\n",
       "      <td>双胶纸</td>\n",
       "      <td>60</td>\n",
       "      <td>北京市</td>\n",
       "      <td>28000</td>\n",
       "      <td>2019</td>\n",
       "      <td>38000</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>525</td>\n",
       "      <td>8010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    页数   类别  彩印   纸张  价格  出版地     字数  出版时间   印刷数量  作者平均年龄  印张  印刷次数  版本  作者数量  \\\n",
       "0  207  技术类   0  双胶纸  60  北京市  51000  2019  35000      40  26     1   2     1   \n",
       "1  210  技术类   0  双胶纸  62  北京市  25000  2019  48000      51  20     4   2     4   \n",
       "2  206  技术类   0  双胶纸  62  北京市  88000  2019  27000      50  22     3   1     3   \n",
       "3  218  技术类   0  双胶纸  64  北京市  21000  2019  20000      39  26     3   2     2   \n",
       "4  209  技术类   0  双胶纸  60  北京市  28000  2019  38000      35  20     2   2     2   \n",
       "\n",
       "   月销售量  累计销售量  \n",
       "0   610   2920  \n",
       "1   141    410  \n",
       "2   498  10080  \n",
       "3   396   8760  \n",
       "4   525   8010  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"产品定价预测.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过value_counts()函数查看这1000本图书有哪些类别及各个类别对应的比例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "技术类    336\n",
       "教辅类    333\n",
       "办公类    331\n",
       "Name: 类别, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"类别\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    648\n",
       "1    352\n",
       "Name: 彩印, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"彩印\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "双胶纸    615\n",
       "铜版纸    196\n",
       "书写纸    189\n",
       "Name: 纸张, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"纸张\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为“类别”和“纸张”两列是分类型文本变量，因此可以采用 **LabelEncoder()函数**对分类变量进行编号，以便于后续的模型拟合:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>页数</th>\n",
       "      <th>类别</th>\n",
       "      <th>彩印</th>\n",
       "      <th>纸张</th>\n",
       "      <th>价格</th>\n",
       "      <th>出版地</th>\n",
       "      <th>字数</th>\n",
       "      <th>出版时间</th>\n",
       "      <th>印刷数量</th>\n",
       "      <th>作者平均年龄</th>\n",
       "      <th>印张</th>\n",
       "      <th>印刷次数</th>\n",
       "      <th>版本</th>\n",
       "      <th>作者数量</th>\n",
       "      <th>月销售量</th>\n",
       "      <th>累计销售量</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>51000</td>\n",
       "      <td>2019</td>\n",
       "      <td>35000</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>2019</td>\n",
       "      <td>48000</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>88000</td>\n",
       "      <td>2019</td>\n",
       "      <td>27000</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>498</td>\n",
       "      <td>10080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>21000</td>\n",
       "      <td>2019</td>\n",
       "      <td>20000</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>28000</td>\n",
       "      <td>2019</td>\n",
       "      <td>38000</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>525</td>\n",
       "      <td>8010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    页数  类别  彩印  纸张  价格  出版地     字数  出版时间   印刷数量  作者平均年龄  印张  印刷次数  版本  作者数量  \\\n",
       "0  207   1   0   1  60    0  51000  2019  35000      40  26     1   2     1   \n",
       "1  210   1   0   1  62    0  25000  2019  48000      51  20     4   2     4   \n",
       "2  206   1   0   1  62    0  88000  2019  27000      50  22     3   1     3   \n",
       "3  218   1   0   1  64    0  21000  2019  20000      39  26     3   2     2   \n",
       "4  209   1   0   1  60    0  28000  2019  38000      35  20     2   2     2   \n",
       "\n",
       "   月销售量  累计销售量  \n",
       "0   610   2920  \n",
       "1   141    410  \n",
       "2   498  10080  \n",
       "3   396   8760  \n",
       "4   525   8010  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"纸张\"] = le.fit_transform(df[\"纸张\"])\n",
    "df[\"类别\"] = le.fit_transform(df[\"类别\"])\n",
    "df[\"出版地\"] = le.fit_transform(df[\"出版地\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过如下代码将特征变量和目标变量单独提取出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"价格\")\n",
    "y = df[\"价格\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取完特征变量后需要将数据拆分为训练集及测试集。划分训练集和测试集的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分为训练集和测试集之后，就可以从Scikit-Learn库中引入GBDT模型进行模型训练了，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=123)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state=123)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 模型预测与评估\n",
    "\n",
    "模型搭建完毕后，通过如下代码对测试集进行预测和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率= 0.8635177501230035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "score = model.score(X_test,y_test)\n",
    "print(\"模型预测准确率=\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过如下代码汇总预测值和实际值，以便进行对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>预测值</th>\n",
       "      <th>实际值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.690895</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.231523</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.128128</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.075714</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.885414</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         预测值  实际值\n",
       "0  71.690895   75\n",
       "1  80.231523   84\n",
       "2  69.128128   68\n",
       "3  90.075714   90\n",
       "4  79.885414   85"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame()    # 创建一个空DataFrame\n",
    "a[\"预测值\"] = list(y_pred)\n",
    "a[\"实际值\"] = list(y_test)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过如下代码可以求得此时系统的均方误差 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.79112684272617"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更科学合理地对产品定价，可以通过如下代码查看各个特征变量的特征重要性，以变筛选出对价格影响最大的特征变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46629718, 0.43693658, 0.04086886, 0.01509174, 0.        ,\n",
       "       0.00837409, 0.        , 0.0047392 , 0.00261408, 0.00169454,\n",
       "       0.00204458, 0.00048581, 0.00102289, 0.01280327, 0.00702719])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，重要性最高的是“页数”和“类别”，一般来说，页数越多的图书价格越高，技术类和办公类图书的价格略高于教辅类图书的价格。“彩印”和“纸张”的重要性较低，对图书价格的影响较小。\n",
    "\n",
    "基于决策树的算法都可以输出特征的重要度，其中sklearn中GBDT的特征重要度函数为feature_importances_，lightgbm中的特征重要度函数为feature_importance，这里以sklearn中的GBDT为例，输出特征重要度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_name  importance\n",
      "0            页数    0.466297\n",
      "1            类别    0.436937\n",
      "2            彩印    0.040869\n",
      "3            纸张    0.015092\n",
      "13         月销售量    0.012803\n",
      "5            字数    0.008374\n",
      "14        累计销售量    0.007027\n",
      "7          印刷数量    0.004739\n",
      "8        作者平均年龄    0.002614\n",
      "10         印刷次数    0.002045\n",
      "9            印张    0.001695\n",
      "12         作者数量    0.001023\n",
      "11           版本    0.000486\n",
      "4           出版地    0.000000\n",
      "6          出版时间    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]   # 用来正常显示中文标签\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False     # 解决负号\"-\"显示为方块的问题\n",
    "\n",
    "def plot_feature_importance(dataset, model_bst):\n",
    "    list_feature_name = list(dataset.columns[:])\n",
    "    # list_feature_importance = list(model_bst.feature_importance(importance_type='split', iteration=-1))\n",
    "    list_feature_importance = list(model_bst.feature_importances_)\n",
    "    dataframe_feature_importance = pd.DataFrame(\n",
    "        {'feature_name': list_feature_name, 'importance': list_feature_importance})\n",
    "    dataframe_feature_importance20 = dataframe_feature_importance.sort_values(by='importance', ascending=False)[:20]\n",
    "    print(dataframe_feature_importance20)\n",
    "    x = range(len(dataframe_feature_importance20['feature_name']))\n",
    "    plt.xticks(x, dataframe_feature_importance20['feature_name'], rotation=90, fontsize=8)\n",
    "    plt.plot(x, dataframe_feature_importance20['importance'])\n",
    "    plt.xlabel(\"Feature name\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.title(\"The importance of features\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]   # 用来正常显示中文标签\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False     # 解决负号\"-\"显示为方块的问题\n",
    "\n",
    "plot_feature_importance(X_train,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GDBT 模型参数调优\n",
    "\n",
    "前面搭建的 GDBT 模型使用的是默认参数，其预测效果已经很不错了，如果进行参数调优，先来了解该模型的参数。在 Jupyter Notebook 中，可以输入并运行如下代码来查看官方文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#GradientBoostingRegressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|参数|含义|取值|\n",
    "|:---:|:---:|:---:|\n",
    "|loss|损失函数|取值为'ls'代表均方差损失函数，取值为'lad'代表绝对损失函数，取值为'huber'代表Huber损失函数，取值为'quantile'代表分位数损失函数，默认取均方差损失函数'ls'|\n",
    "|learning_rate|弱学习器的权重缩减系数ν|取值范围为(0,1]，默认取0.1|\n",
    "|n_estimators|弱学习器的最大迭代次数|取值为int型数据，默认取100|\n",
    "|subsample|子采样比率|为了防止GBDT模型发生过拟合建立每棵回归树时采用子采样，该参数取值范围为(0,1]；取值为1代表在建立回归树时使用所有样本，取值小于1代表通过不放回抽样使用部分样本；默认取1|\n",
    "|criterion|特征选择标准|取值为string型，默认为'friedman_mse'。'friedman_mse'是费尔德曼均方误差，'mse'是均方误差，'mae'是平均绝对误差|\n",
    "|min_samples_split|分割内部节点所需要的最小样本数量|取值为int型或者float型。如果为整数，那么该值为最小样本数量；如果为浮点型，这是一个百分比。默认为2|\n",
    "|min_samples_leaf|叶子节点上的最小样本数量|取值为int型或者float型。如果为整数，那么该值为最小样本数量；如果为浮点型，这是一个百分比，默认为1|\n",
    "|min_weight_fraction_leaf|叶子节点最小的样本权重和|默认取0，即不考虑权重问题，如果小于该数值，该叶子节点会和兄弟节点一起被剪枝（即剔除该叶子节点和其兄弟节点，并停止分裂）。如果较多样本有缺失值或者样本的分布类别偏差很大，则需考虑样本权重问题。|\n",
    "|max_depth|最大深度|取值为int型，最大深度限制了树的节点数，默认为3|\n",
    "|min_impurity_decrease|分裂节点阈值|如果节点的分裂导致不纯度的下降大于或等于该参数，则分裂该节点，浮点型，默认为0|\n",
    "|min_impurity_split|停止树生长的阈值|如果节点的不纯度高于阈值，就进行分裂，否则就是叶子节点；取值为float型，默认为1e-7|\n",
    "|random_state|设定随机状态|取值范围为：{int整数, RandomState实例, None}。如果为整数，则指定了随机数生成器的种子，设置为任意整数后，例如“123”，则每次运行的结果都是一致的；如果为RandomState实例，则指定了随机数生成器；如果为None，则使用默认的随机数生成器。默认为None|\n",
    "|max_features|寻找最佳切割时要考虑的特征数量|int型，float型，string型或者None，如果为int型，代表要考虑的特征数量；如果为float型，即百分比；如果为'auto'，代表sqrt(n_features)；如果为'sqrt'，和'auto'一样；如果为'log2'，代表log2(n_features)；如果为None,代表n_features；默认取'None'|\n",
    "|verbose|控制输出|整数型，默认为0，如果为0则不输出日志，如果为1，则每隔一段时间输出日志，大于1输出日志会更频繁|\n",
    "|max_leaf_nodes|最大叶子节点数|取值为int型数据，默认为None|\n",
    "|warm_start|热启动|布尔型，设置为True时，重用前一个调用的解决方案以适合初始化，否则只擦除前一个解决方案，默认为False|\n",
    "|presort|数据预排序|指定是否需要提前对数据进行排序从而加速寻找最优切分点。设置为True时，在数据量大时会减慢总体的训练过程，但对于小数据集或者设定了最大深度的情况下，则会加速训练过程|\n",
    "|validation_fraction|留作早期停止的验证集训练数据的比例|float型，默认为0.1|\n",
    "|n_iter_no_change|确定当验证分数没有提高时是否提前停止训练|取值为int型，默认为None。取值为None时，禁止提前停止训练；取值为整数时，将保留'validation_fraction'的数据用作验证，并在验证得分在之前'n_iter_no_change_'轮迭代中没有提高时终止训练|\n",
    "|tol|提前停止训练的条件|取值为float型，默认为1e-4。损失改善小于tol时，训练停止|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **（1）网格搜索（GridSearchCV）**\n",
    "\n",
    "首先我们从步长(learning rate)和迭代次数(n_estimators)入手。一般来说，开始选择一个较小的步长来网格搜索最好的迭代次数。这里，我们将步长初始值设置为0.1。对于迭代次数进行网格搜索如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3, 'n_estimators': 80}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"n_estimators\":[20,30,40,50,60,80], \"learning_rate\":[0.05, 0.1, 0.2, 0.3,0.5,1]}\n",
    "model =  GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(model, parameters,  cv=5)\n",
    "grid_search.fit(X,y)     # 传入数据\n",
    "grid_search.best_params_             # 输出参数的最优值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率= 0.8697811585550834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model2 = GradientBoostingRegressor(n_estimators=80,learning_rate=0.3)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "score = model2.score(X_test,y_test)\n",
    "print(\"模型预测准确率=\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **（2）贝叶斯优化器（bayesian  optimization)**\n",
    "\n",
    "python用户可以采用下方命令行可以快速的安装贝叶斯调试利器—— bayesian-optimization\n",
    "\n",
    "pip install -i https://mirrors.aliyun.com/pypi/simple bayesian-optimization\n",
    "\n",
    "贝叶斯优化器需要定义好贝叶斯调参的目标函数，以及参数空间的范围。运行gbdt_op.maximize()，就可以开始用贝叶斯优化去搜索最优参数空间了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'just_fix_windows_console' from 'colorama' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\colorama\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ee8e1d4a5f22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgbdt_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     res = cross_val_score( \n\u001b[0;32m      5\u001b[0m         GradientBoostingRegressor(n_estimators=int(n_estimators),\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bayes_opt\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbayesian_optimization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdomain_reduction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequentialDomainReductionTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUtilityFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mScreenLogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJSONLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConstraintModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConstraintModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtarget_space\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTargetSpace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_EVENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_get_default_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensure_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotUniqueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColours\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bayes_opt\\util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcolorama\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjust_fix_windows_console\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'just_fix_windows_console' from 'colorama' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\colorama\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "def gbdt_cv(n_estimators, min_samples_split, max_features, max_depth):\n",
    "    res = cross_val_score( \n",
    "        GradientBoostingRegressor(n_estimators=int(n_estimators),\n",
    "                                                        min_samples_split=int(min_samples_split),\n",
    "                                                        max_features=min(max_features, 0.999), # float\n",
    "                                                        max_depth=int(max_depth),\n",
    "                                                        random_state=2\n",
    "        ),\n",
    "        X_train, y_train, cv=20\n",
    "    ).mean()\n",
    "    return res\n",
    "\n",
    "gbdt_op = BayesianOptimization(\n",
    "        gbdt_cv,\n",
    "        {'n_estimators': (10, 250),\n",
    "        'min_samples_split': (2, 25),\n",
    "        'max_features': (0.1, 0.999),\n",
    "        'max_depth': (5, 15)}\n",
    "    )\n",
    "\n",
    "gbdt_op.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbdt_op.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上方是调参过程，我们可以看到，各参数空间所对应的得分，以及每个参数空间的具体数值情况。把相应最优参数代入GBDT回归模型，然后对模型进行训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model3 = GradientBoostingRegressor(n_estimators=48,min_samples_split=25,\n",
    "                                  max_features=0.999,max_depth=5)\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "score = model3.score(X_test,y_test)\n",
    "print(\"模型预测准确率=\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus']=False    #解决负数坐标显示问题\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "def plot_learning_curves(model, X,y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors),\"b-\",linewidth=3, label=\"val\")\n",
    "    \n",
    "lin_reg =GradientBoostingRegressor(n_estimators=48,min_samples_split=25,\n",
    "                                  max_features=0.999,max_depth=5)\n",
    "plot_learning_curves(lin_reg, X, y)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"学习曲线\")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "clf =AdaBoostRegressor(random_state=123)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"模型预测准确率=\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame()    # 创建一个空DataFrame\n",
    "a[\"预测值\"] = list(y_pred)\n",
    "a[\"实际值\"] = list(y_test)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"n_estimators\":[20,30,40,50,60,80], \"learning_rate\":[0.05, 0.1, 0.2, 0.3,0.5,1]}\n",
    "model = AdaBoostRegressor()\n",
    "grid_search = GridSearchCV(model, parameters,  cv=5)\n",
    "grid_search.fit(X,y)     # 传入数据\n",
    "grid_search.best_params_             # 输出参数的最优值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model2 = AdaBoostRegressor(n_estimators=80,learning_rate=1)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "score = model2.score(X_test,y_test)\n",
    "print(\"模型预测准确率=\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "def gbdt_cv(n_estimators):\n",
    "    res = cross_val_score( \n",
    "        AdaBoostRegressor(n_estimators=int(n_estimators), random_state=2\n",
    "        ),\n",
    "        X_train, y_train, cv=20\n",
    "    ).mean()\n",
    "    return res\n",
    "\n",
    "gbdt_op = BayesianOptimization(\n",
    "        gbdt_cv,\n",
    "        {'n_estimators': (10, 250),\n",
    "       }\n",
    "    )\n",
    "\n",
    "gbdt_op.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbdt_op.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model3 = AdaBoostRegressor(n_estimators=10,learning_rate=1)\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "score = model3.score(X_test,y_test)\n",
    "print(\"模型预测准确率=\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus']=False    #解决负数坐标显示问题\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "def plot_learning_curves(model, X,y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors),\"b-\",linewidth=3, label=\"val\")\n",
    "    \n",
    "lin_reg =AdaBoostRegressor(n_estimators=10,learning_rate=1)\n",
    "plot_learning_curves(lin_reg, X, y)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"学习曲线\")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
